{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7a778117",
   "metadata": {},
   "source": [
    "## DA 320 \n",
    "\n",
    "| Key         | Value |\n",
    "| ----------- | ----------- |\n",
    "| Assignment  | Basics of Web Scraping  |\n",
    "| Author   | Ted Spence        |\n",
    "| Date   | 2022-10-13        |\n",
    "\n",
    "This is an example of a markdown header segment in a Jupyter notebook with a nice table.\n",
    "\n",
    "***\n",
    "# Check whether Jupyter and Python are installed correctly\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4de6aa37-686f-4a0f-a474-29958b86bc89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello, world!\n"
     ]
    }
   ],
   "source": [
    "# A basic Python command you can use to verify that Python is running correctly\n",
    "print(\"Hello, world!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fce08a0",
   "metadata": {},
   "source": [
    "***\n",
    "# Use \"Pip Install\" within a Jupyter Notebook\n",
    "***\n",
    "\n",
    "The next code segment demonstrates how you can use `pip install` within a notebook.\n",
    "\n",
    "Note that if you have *any* python code at all in the same segment with the `pip install` command, it won't work!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0a2f2628",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: urllib3 in /opt/homebrew/lib/python3.10/site-packages (1.26.12)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install urllib3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d72d7483",
   "metadata": {},
   "source": [
    "***\n",
    "# Retrieve connection strings, passwords, or secrets from a JSON file \n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ca94844-e6d3-44a1-92b8-d60b17ee36e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# Demonstration of how to load a file that contains secrets without accidentally leaking those secrets\n",
    "with open('f:\\\\git\\\\teds-secrets.json') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "    # If you want your data to be secure, don't print this variable out!\n",
    "    # Jupyter will retain a cached version of any printed data and it can be\n",
    "    # accidentally committed to version control.\n",
    "    secret_key = data['my-secret-key']\n",
    "\n",
    "# We can safely print the length of the secret key. That won't leak any sensitive information.\n",
    "print(f\"My secret key is {len(secret_key)} characters in length.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45874af7",
   "metadata": {},
   "source": [
    "***\n",
    "# Fetch the contents of a webpage\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc8ef5e7-891a-46a1-a4e8-96114aed18a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetched 73183 characters from https://www.wikipedia.org/ (status: 200)\n"
     ]
    }
   ],
   "source": [
    "import urllib3\n",
    "import certifi\n",
    "\n",
    "# Demonstration of how to fetch text from a website using certifi, urllib3, and UTF-8 encoding.\n",
    "# This also simulates a browser agent.\n",
    "# Adapted from https://tedspence.com/teaching-python-and-jupyter-cbffb68e2194\n",
    "\n",
    "# This line of code generates a pool for HTTP requests.  Pooling means that a second request to the same\n",
    "# website will be faster than the first one since it will retain an open connection for a period of time.\n",
    "http = urllib3.PoolManager(ca_certs=certifi.where())\n",
    "\n",
    "# These lines of code choose which website we will fetch and which browser we will simulate.\n",
    "url = 'https://www.wikipedia.org/'\n",
    "user_agent = \"Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:105.0) Gecko/20100101 Firefox/105.0\"\n",
    "\n",
    "# This instruction requests the contents of the page and decodes it using UTF-8, the standard text\n",
    "# encoding model for the Internet today.\n",
    "response = http.request('GET', url, headers={\"User-Agent\": user_agent})\n",
    "page_content = response.data.decode('utf-8')\n",
    "\n",
    "# Print out what we achieved!\n",
    "print(f\"Fetched {len(page_content)} characters from {url} (status: {response.status})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46fd4d46",
   "metadata": {},
   "source": [
    "***\n",
    "# Searching for facts within text using Regular Expressions\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08d606a9-bece-41ad-b990-4069b9551475",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1 matches.  The first match is 'fox'.\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "# Here is the text we will search\n",
    "content = \"The quick brown fox jumps over the lazy dog.\"\n",
    "\n",
    "# This defines our regular expression. You can use https://regex101 as a great test site!\n",
    "regular_expression = r\"quick brown (.*) jumps\"\n",
    "\n",
    "# Demonstration of how to search and find matches within some text\n",
    "matches = re.findall(regular_expression, content)\n",
    "print(f\"Found {len(matches)} matches.  The first match is '{matches[0]}'.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e589b8b",
   "metadata": {},
   "source": [
    "***\n",
    "# Formatting Output using Pandas DataFrames\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bae5b490-6f1c-460e-ba82-8fadafef7049",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>City</th>\n",
       "      <th>Year Founded</th>\n",
       "      <th>Population 2020</th>\n",
       "      <th>Thumbnail</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Seattle</td>\n",
       "      <td>1851</td>\n",
       "      <td>737015</td>\n",
       "      <td><img src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/7/7e/Downtown_Seattle_skyline_from_Kerry_Park_-_October_2019.jpg/536px-Downtown_Seattle_skyline_from_Kerry_Park_-_October_2019.jpg\" width=\"60\" /></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Bellevue</td>\n",
       "      <td>1953</td>\n",
       "      <td>151854</td>\n",
       "      <td><img src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/9/9a/BellevueAndSeattle.jpg/560px-BellevueAndSeattle.jpg\" width=\"60\" /></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Redmond</td>\n",
       "      <td>1912</td>\n",
       "      <td>73256</td>\n",
       "      <td><img src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/1/16/Bicycle_Capital_of_the_Northwest.JPG/1600px-Bicycle_Capital_of_the_Northwest.JPG\" width=\"60\" /></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from IPython.core.display import HTML\n",
    "\n",
    "# Construct a Pandas dataframe using named columns\n",
    "dataset = {\n",
    "    \"City\": ['Seattle', 'Bellevue', 'Redmond'], \n",
    "    \"Year Founded\": [1851, 1953, 1912], \n",
    "    \"Population 2020\": [737015, 151854, 73256],\n",
    "    \"Thumbnail\": ['https://upload.wikimedia.org/wikipedia/commons/thumb/7/7e/Downtown_Seattle_skyline_from_Kerry_Park_-_October_2019.jpg/536px-Downtown_Seattle_skyline_from_Kerry_Park_-_October_2019.jpg', 'https://upload.wikimedia.org/wikipedia/commons/thumb/9/9a/BellevueAndSeattle.jpg/560px-BellevueAndSeattle.jpg', 'https://upload.wikimedia.org/wikipedia/commons/thumb/1/16/Bicycle_Capital_of_the_Northwest.JPG/1600px-Bicycle_Capital_of_the_Northwest.JPG']\n",
    "    }\n",
    "dataFrame = pd.DataFrame(dataset)\n",
    "\n",
    "# Create a formatter to convert URLs into inline images\n",
    "def path_to_image_html(path: str):\n",
    "    return f\"<img src=\\\"{path}\\\" width=\\\"60\\\" />\"\n",
    "\n",
    "# Format the pandas dataframe to output using the formatter we created\n",
    "formatters = dict(Thumbnail = path_to_image_html)\n",
    "html = dataFrame.to_html(escape = False, formatters = formatters)\n",
    "HTML(html)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "b0fa6594d8f4cbf19f97940f81e996739fb7646882a419484c72d19e05852a7e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
