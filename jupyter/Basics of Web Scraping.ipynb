{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7a778117",
   "metadata": {},
   "source": [
    "## DA 320 \n",
    "\n",
    "| Key         | Value |\n",
    "| ----------- | ----------- |\n",
    "| Assignment  | Basics of Web Scraping  |\n",
    "| Author   | Ted Spence        |\n",
    "| Date   | 2022-10-13        |\n",
    "\n",
    "This example notebook contains tutorials on the basic usage of web scraping techniques."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45874af7",
   "metadata": {},
   "source": [
    "***\n",
    "# Fetch the contents of a webpage\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc8ef5e7-891a-46a1-a4e8-96114aed18a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib3\n",
    "import certifi\n",
    "\n",
    "# Demonstration of how to fetch text from a website using certifi, urllib3, and UTF-8 encoding.\n",
    "# This also simulates a browser agent.\n",
    "# Adapted from https://tedspence.com/teaching-python-and-jupyter-cbffb68e2194\n",
    "\n",
    "# This line of code generates a pool for HTTP requests.  Pooling means that a second request to the same\n",
    "# website will be faster than the first one since it will retain an open connection for a period of time.\n",
    "http = urllib3.PoolManager(ca_certs=certifi.where())\n",
    "\n",
    "# These lines of code choose which website we will fetch and which browser we will simulate.\n",
    "url = 'https://www.wikipedia.org/'\n",
    "user_agent = \"Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:105.0) Gecko/20100101 Firefox/105.0\"\n",
    "\n",
    "# This instruction requests the contents of the page and decodes it using UTF-8, the standard text\n",
    "# encoding model for the Internet today.\n",
    "response = http.request('GET', url, headers={\"User-Agent\": user_agent})\n",
    "page_content = response.data.decode('utf-8')\n",
    "\n",
    "# Print out what we achieved!\n",
    "print(f\"Fetched {len(page_content)} characters from {url} (status: {response.status})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ea478cf",
   "metadata": {},
   "source": [
    "***\n",
    "# Fetch the contents of multiple pages in a loop\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdbf881c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib3\n",
    "import certifi\n",
    "\n",
    "# Construct an HTTP request pool to make multiple page fetches faster\n",
    "http = urllib3.PoolManager(ca_certs=certifi.where())\n",
    "\n",
    "# Loop through the years 1914 - 1918 and gather data from wikipedia.\n",
    "# Note that Python ranges stop *before* the final number.\n",
    "for year in range(1914, 1919):\n",
    "    print(f\"Collecting data for {year}...\")\n",
    "    url = f\"https://en.wikipedia.org/wiki/{year}\"\n",
    "    response = http.request('GET', url, headers={'User-Agent': 'Mozilla/5.0'})\n",
    "    page_content = str(response.data, \"utf-8\")\n",
    "\n",
    "    # Here is where we would apply regular expressions to the page content\n",
    "    print(f\"Fetched {len(page_content)} characters from {url} (status: {response.status})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46fd4d46",
   "metadata": {},
   "source": [
    "***\n",
    "# Searching for facts within text using Regular Expressions\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08d606a9-bece-41ad-b990-4069b9551475",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "# Here is the text we will search\n",
    "content = \"The quick brown fox jumps over the lazy dog.\"\n",
    "\n",
    "# This defines our regular expression. You can use https://regex101 as a great test site!\n",
    "regular_expression = r\"quick brown (.*) jumps\"\n",
    "\n",
    "# Demonstration of how to search and find matches within some text\n",
    "matches = re.findall(regular_expression, content)\n",
    "print(f\"Found {len(matches)} matches.  The first match is '{matches[0]}'.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efb3e92e",
   "metadata": {},
   "source": [
    "***\n",
    "# Formatting output using a loop\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b19dac16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using a loop is the simplest form of printing tabular data.\n",
    "\n",
    "# Construct a Pandas dataframe using named columns\n",
    "cities = ['Seattle', 'Bellevue', 'Redmond']\n",
    "founded = [1851, 1953, 1912]\n",
    "population = [737015, 151854, 73256]\n",
    "\n",
    "# Loop through the dataset starting at position zero\n",
    "for i in range(0, 3):\n",
    "    print(f\"City {cities[i]} was founded in {founded[i]} and has a population of {population[i]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e589b8b",
   "metadata": {},
   "source": [
    "***\n",
    "# Formatting Output using Pandas DataFrames\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bae5b490-6f1c-460e-ba82-8fadafef7049",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from IPython.core.display import HTML\n",
    "\n",
    "# Construct a Pandas dataframe using named columns\n",
    "dataset = {\n",
    "    \"City\": ['Seattle', 'Bellevue', 'Redmond'], \n",
    "    \"Year Founded\": [1851, 1953, 1912], \n",
    "    \"Population 2020\": [737015, 151854, 73256],\n",
    "    \"Thumbnail\": ['https://upload.wikimedia.org/wikipedia/commons/thumb/7/7e/Downtown_Seattle_skyline_from_Kerry_Park_-_October_2019.jpg/536px-Downtown_Seattle_skyline_from_Kerry_Park_-_October_2019.jpg', 'https://upload.wikimedia.org/wikipedia/commons/thumb/9/9a/BellevueAndSeattle.jpg/560px-BellevueAndSeattle.jpg', 'https://upload.wikimedia.org/wikipedia/commons/thumb/1/16/Bicycle_Capital_of_the_Northwest.JPG/1600px-Bicycle_Capital_of_the_Northwest.JPG']\n",
    "    }\n",
    "dataFrame = pd.DataFrame(dataset)\n",
    "\n",
    "# Create a formatter to convert URLs into inline images\n",
    "def path_to_image_html(path: str):\n",
    "    return f\"<img src=\\\"{path}\\\" width=\\\"60\\\" />\"\n",
    "\n",
    "# Format the pandas dataframe to output using the formatter we created\n",
    "formatters = dict(Thumbnail = path_to_image_html)\n",
    "html = dataFrame.to_html(escape = False, formatters = formatters)\n",
    "HTML(html)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.3 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.3"
  },
  "vscode": {
   "interpreter": {
    "hash": "054b8a8ab1859522654f24f6469821b8b13c4a0fd8db908465293addbf3bdc9b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
